# Crítica : Collaborative filtering recommender systems. In The adaptive web
En este paper los autores explican en que consisten los sistemas recomendados de Filtrado Colaborativo, los cuales, a groso modo, emulan una conducta intrínseca del ser Humano: compartir opiniones con otros.  Es decir, estos sistemas se basan en evaluar y filtrar *ítems* para recomendar, a través de la opinión de una comunidad interconectada. Para explicar todo lo anteriormente mencionado, los autores expresan en primera instancia la funcionalidad de esta forma de recomendar, luego, los diversos algoritmos que son utilizados, posteriormente, cómo los diversos tipos de escala de evaluación afectan el algoritmo, también explican como evaluar y comparar recomendados y finalmente, algunos retos que posee por delante el algoritmo y algunas preguntas abiertas sobre el mismo.

En un primer análisis, me pareció que el algoritmo es bastante sencillo y fácil de comprender, sin embargo, me parece extremadamente limitado en ciertas circunstancias. Por ejemplo, se debe tener una base de datos con evaluaciones  "robusta", es decir, deben existir suficientes evaluaciones para poder hacer una recomendación precisa, deben existir suficientes *ítems* que recomendar y además que usuarios hayan evaluado una cantidad variada de *ítems*. Esto último, debido a que en un algoritmo basado en la cercanía de usuarios, si hay usuarios que tienen pocas evaluaciones, estos podrían tener como vecinos (con coeficiente de correlación de Pearson muy alto ó cercano a 1)  a otros usuarios que comparten los mismos gustos por un grupo limitado de *ítems*, sin embargo, podrían tener gustos completamente distintos en todo el resto de *ítems* de un *pool*, lo que llevaría al algoritmo a fallar en una recomendación y/o predicción.

Siguiendo la misma linea, me parece que el algoritmo es muy propenso a caer en el *sesgo de supervivencia*, es decir, dado un subconjunto de *ítems*, puede ocurrir que existan evaluaciones similares para todo el subconjunto y si se elimina alguna de estas evaluaciones, probablemente, no existan cambios dentro de la recomendación de alguno de estos ítems, o incluso mejore la precisión de la recomendación, sin embargo, esto no significa que el algoritmo actue mejor, debido a que fuera de este subconjunto, es posible, que las predicciones y recomendaciones empeoren.

Por otra parte, el algoritmo no se hace cargo de la heterogeneidad social y como se construyen paradigmas dentro de una sociedad. Esto, debido a que pueden existir grupos con gustos muy similares, pero cambios abruptos en contextos sociales específicos para cada grupo puede llevar a que de forma muy rápida cambien las preferencias de las personas y con ello, afectar la predicción ó recomendaciones para grupos que no están afectos a estos cambios. Por lo tanto, los *ítems* que parecían tener un componente de gusto que no variaba mucho durante tiempo, se vuelvan muy volátil rápidamente afectando la recomendación para otras comunidades.

Otro aspecto a mencionar es que a pesar de que se necesitan una basta cantidad de datos, tampoco puede ser un numero exageradamente grande, debido a los requerimientos computaciones que requiere el algoritmo. Una gran cantidad de datos podría llevarnos a emplear técnicas de reducción de dimensionalidad, las cuales son costosas y podrían entorpecer la eficiencia del algoritmo.

Dentro de las métricas de rendimiento, me pareció curioso que no incluyera como forma de medir rendimiento el error de generalización de las predicciones, es decir, la probabilidad de que una evaluación real otorgada al *ítem* fuese distinta a la predicha para el mismo. Esto permitiría comprender aún más como se están prediciendo las calificaciones y como se puede ajustar la predicción de las mismas.

Finalmente, considero que el algoritmo es una muy buena primera instancia para recomendar ítems en base a la comunidad y me parece que este paper está mucho mejor explicado y desarrollado comparado con 'Item-Based Collaborative Filtering Recommendation Algorithms' de Sarwar, Badrul, Karypis, et al. en el cual se utiliza la misma idea de recomendacion en base a la correlacion de pearson. El paper obligatorio es más fácil de comprender, más útil, debido a que nos entrega una "chance" de afinidad para cierto *ítem*, muy versátil, ya que a que no depende de la escala de calificación otorgada a cada *ítem* ( la escala funciona arbitrariamente), y  es adaptable a la base de datos y necesidades computacionales, debido a que existen diversas formas de emplear el algoritmo.
