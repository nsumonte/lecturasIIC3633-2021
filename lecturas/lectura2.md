# Crítica : MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS.
En este paper, Yehuda Koren, Robert Bell y Chris Volinsky hablan de la factorización matricial como método de recomendación. Esto es, a grandes rasgos, generar características latentes a través del producto interno de vectores que describan dos tipos de entidades. Para esto, los autores comienzan describiendo el contexto histórico del problema, la caracterización del mismo, se especifica SVD en sistemas recomendadores , se muestran los algoritmos de aprendizaje y finalmente se entregan algunas extensiones para el problema.

En primer lugar, el método explicado por los autores me parece un modelo bastante robusto comparado con los otros ya vistos en el curso, y además me pareció bastante buena la forma de contextualizar el problema y como se contrastó el mismo con ejemplos reales como el de la ***Netflix Price competition.*** Me parece muy bueno que el modelo permita agregar un factor de sesgo y además poder considerar un componente temporal, todo esto, debido a que los gustos no son estáticos y dependen de muchos factores que son variables en el tiempo.

En un segundo análisis me parece que el paper no responde a ciertos problemas que se podrían generar con la matriz de características para el buen funcionamiento de SVD. Por ejemplo, si el numero de condicionamiento de la matriz ( ratio de valor propio mayor y menor) es muy alto, esto generará que el proceso sea muy costoso computacionalmente, e inclusive, si la matriz esta muy cercana a ser singular, puede que no se pueda llevar a cabo el proceso.

En tercer lugar, me parece que se debió porlomenos comentar el porque se usa como método de optimización el algoritmo del gradiente estocastico y porqué no otro como el método de newton o de punto interior que tienen una convergencia mas rápida que el método de gradiente ( A mí parecer, creo que esto se debe a que estos últimos métodos necesitan calcular el hessiano de la matriz de características latentes lo que no siempre es posible, sin embargo, en ocasiones estos métodos pueden ser una opción viable y no se menciona como extensión).

Finalmente, me gustaría resaltar lo expuesto por Rendle, Freudenthaler, Gantner y Schmidt-Thieme en BPR: Bayesian Personalized Ranking from Implicit Feedback, esto, debido a que para encontrar una la fractorización matricial de la matriz de factores latentes utilizan métodos Bayesianos. Esto me parece correcto, ya que en vez de asumir una estimación puntual para cada vector de una clase en particular, entregan una distribución de probabilidad del mismo, haciéndose cargo de cierta forma, de la incertidumbre que conlleva el no conocer todas las características de la matriz de características latentes. Además utilizando estadística bayesiana, se demostró empíricamente que el método del gradiente estocastico mejora significativamente la tasa de convergencia del método de factorización matricial.


